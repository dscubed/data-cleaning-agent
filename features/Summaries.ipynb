{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "691226d2",
   "metadata": {},
   "source": [
    "## **Feature:** Dataset Summaries\n",
    "\n",
    "**Names:** Dhruv\n",
    "\n",
    "### **What it does**\n",
    "Generates statistical summaries including descriptive statistics (mean, median, mode, variance, std, quartiles), distribution analysis, correlation matrices, and basic visualisations for dataset exploration.\n",
    "\n",
    "### **Helper Functions**\n",
    "- calculate_basic_stats(df, columns=None): Calculate mean, median, std, variance, skewness, kurtosis for numeric columns\n",
    "- calculate_five_number_summary(df, columns=None): Calculate min, Q1, median, Q3, max, IQR for numeric columns\n",
    "- calculate_mode_stats(df, columns=None): Calculate mode, frequency, unique values for all columns\n",
    "- generate_correlation_matrix(df, method='pearson'): Create correlation matrix and heatmap for numeric columns\n",
    "- create_distribution_plots(df, columns=None, max_plots=6): Create histograms for numeric columns\n",
    "- analyze_categorical_columns(df, columns=None, top_n=5): Analyze categorical columns with frequency tables\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1f7555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get API Key\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not OPEN_API_KEY:\n",
    "    print(\"OpenAI API Key not found\")\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import datetime\n",
    "from sklearn import preprocessing, impute\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Langchain imports\n",
    "from langchain.chat_models import ChatOpenAI  \n",
    "from langchain.schema import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60424d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_basic_stats(df, columns=None):\n",
    "    \"\"\"Calculate basic descriptive statistics for numeric columns like mean, median, std, variance, skewness, kurtosis for numeric columns\"\"\"\n",
    "    if columns is None:\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    else:\n",
    "        numeric_cols = [col for col in columns if col in df.columns and df[col].dtype in ['int64', 'float64']]\n",
    "    \n",
    "    stats_dict = {}\n",
    "    for col in numeric_cols:\n",
    "        stats_dict[col] = {\n",
    "            'count': df[col].count(),\n",
    "            'mean': df[col].mean(),\n",
    "            'median': df[col].median(),\n",
    "            'std': df[col].std(),\n",
    "            'variance': df[col].var(),\n",
    "            'min': df[col].min(),\n",
    "            'max': df[col].max(),\n",
    "            'skewness': df[col].skew(),\n",
    "            'kurtosis': df[col].kurtosis()\n",
    "        }\n",
    "    \n",
    "    return pd.DataFrame(stats_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a090e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_five_number_summary(df, columns=None):\n",
    "    \"\"\"Calculate five number summary (min, Q1, median, Q3, max) for numeric columns\"\"\"\n",
    "    if columns is None:\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    else:\n",
    "        numeric_cols = [col for col in columns if col in df.columns and df[col].dtype in ['int64', 'float64']]\n",
    "    \n",
    "    summary_dict = {}\n",
    "    for col in numeric_cols:\n",
    "        summary_dict[col] = {\n",
    "            'min': df[col].min(),\n",
    "            'Q1': df[col].quantile(0.25),\n",
    "            'median': df[col].median(),\n",
    "            'Q3': df[col].quantile(0.75),\n",
    "            'max': df[col].max(),\n",
    "            'IQR': df[col].quantile(0.75) - df[col].quantile(0.25)\n",
    "        }\n",
    "    \n",
    "    return pd.DataFrame(summary_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffed275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mode_stats(df, columns=None):\n",
    "    \"\"\"Calculate mode and frequency statistics for all columns\"\"\"\n",
    "    if columns is None:\n",
    "        columns = df.columns\n",
    "    \n",
    "    mode_stats = {}\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            mode_val = df[col].mode().iloc[0] if not df[col].mode().empty else None\n",
    "            mode_stats[col] = {\n",
    "                'mode': mode_val,\n",
    "                'mode_frequency': df[col].value_counts().iloc[0] if not df[col].value_counts().empty else 0,\n",
    "                'unique_values': df[col].nunique(),\n",
    "                'most_frequent_values': df[col].value_counts().head(3).to_dict()\n",
    "            }\n",
    "    \n",
    "    return mode_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881f15c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_function(df, user_query):\n",
    "    \"\"\"\n",
    "    Main function that gets called by the main router.\n",
    "    MUST take (user_query, df) and return df\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Create helper docs (Reimplement with functions)\n",
    "    helper_docs = \"\"\"\n",
    "    - calculate_basic_stats(df, columns=None): Calculate mean, median, std, variance, skewness, kurtosis for numeric columns\n",
    "    - calculate_five_number_summary(df, columns=None): Calculate min, Q1, median, Q3, max, IQR for numeric columns\n",
    "    - calculate_mode_stats(df, columns=None): Calculate mode, frequency, unique values for all columns\n",
    "    - generate_correlation_matrix(df, method='pearson'): Create correlation matrix and heatmap for numeric columns\n",
    "    - create_distribution_plots(df, columns=None, max_plots=6): Create histograms for numeric columns\n",
    "    - analyze_categorical_columns(df, columns=None, top_n=5): Analyze categorical columns with frequency tables\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create message chain\n",
    "    messages = []\n",
    "    messages.append(SystemMessage(content=f\"\"\"\n",
    "    You are a data cleaning agent.\n",
    "    \n",
    "    Dataset info: Shape: {df.shape}, Sample: {df.head(3).to_string()}\n",
    "    \n",
    "    Helper functions available:\n",
    "    {helper_docs}\n",
    "\n",
    "    Libraries available:\n",
    "    - pd (pandas), np (numpy)\n",
    "    - math, re, datetime\n",
    "    - preprocessing, impute (from sklearn)\n",
    "    - plt (matplotlib.pyplot), sns (seaborn)\n",
    "    - stats (from scipy)\n",
    "    \n",
    "    Rules:\n",
    "    - Return only executable Python code, no explanations, no markdown blocks\n",
    "    - Use helper functions where possible\n",
    "    - Store final result in 'result_df'\n",
    "    - No explanations, just code\n",
    "    \"\"\"))\n",
    "    messages.append(HumanMessage(content=f\"User request: {user_query}\"))\n",
    "    \n",
    "    # Call LLM with message chain\n",
    "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\")\n",
    "    response = llm.invoke(messages)\n",
    "    generated_code = response.content.strip()\n",
    "    \n",
    "    # Execute code\n",
    "    try:\n",
    "        original_df = df.copy()\n",
    "        exec(generated_code)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(f\"Generated Code:{generated_code}\")\n",
    "        return original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b618978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST OUT YOUR FEATURE\n",
    "\n",
    "## Import Data\n",
    "\n",
    "## Run code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-cleaning-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
