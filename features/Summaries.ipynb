{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "691226d2",
   "metadata": {},
   "source": [
    "## **Feature:** Dataset Summaries\n",
    "\n",
    "**Names:** Dhruv\n",
    "\n",
    "### **What it does**\n",
    "Generates statistical summaries including descriptive statistics (mean, median, mode, variance, std, quartiles), distribution analysis, correlation matrices, and basic visualisations for dataset exploration.\n",
    "\n",
    "### **Helper Functions**\n",
    "- calculate_basic_stats(df, columns=None): Calculate mean, median, std, variance, skewness, kurtosis for numeric columns\n",
    "- calculate_five_number_summary(df, columns=None): Calculate min, Q1, median, Q3, max, IQR for numeric columns\n",
    "- calculate_mode_stats(df, columns=None): Calculate mode, frequency, unique values for all columns\n",
    "- generate_correlation_matrix(df, method='pearson'): Create correlation matrix and heatmap for numeric columns\n",
    "- create_distribution_plots(df, columns=None, max_plots=6): Create histograms for numeric columns\n",
    "- analyse_categorical_columns(df, columns=None, top_n=5): Analyse categorical columns with frequency tables\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1f7555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get API Key\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"OpenAI API Key not found\")\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Langchain imports\n",
    "from langchain.chat_models import ChatOpenAI  \n",
    "from langchain.schema import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60424d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_summary(df, columns=None, metrics=None):\n",
    "    \"\"\"\n",
    "    Returns summary dataframe for given columns of numeric type\n",
    "\n",
    "    - params:\n",
    "        - columns: list[str] or None (defaults to numeric columns)\n",
    "        - metrics: list[str] subset of ['count','missing','mean','std', 'var', 'min','median','q1','q3','max','skew','range', 'iqr']\n",
    "    - returns: pd.DataFrame\n",
    "    \"\"\"\n",
    "     \n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Default to numeric columns if no specific columns given\n",
    "    if columns:\n",
    "        columns = [col for col in columns if col in df.columns and pd.api.types.is_numeric_dtype(df[col])]\n",
    "    else:\n",
    "        columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "    if not columns:\n",
    "        return pd.DataFrame\n",
    "\n",
    "    filtered_df = df[columns]\n",
    "\n",
    "    # Default metric set\n",
    "    default_metrics = {\n",
    "        \"count\": filtered_df.count(),\n",
    "        \"missing\": filtered_df.isna().sum(),\n",
    "        \"mean\": filtered_df.mean(),\n",
    "        \"std\": filtered_df.std(),\n",
    "        \"var\": filtered_df.var(),\n",
    "        \"min\": filtered_df.min(),\n",
    "        \"q1\": filtered_df.quantile(0.25),\n",
    "        \"median\": filtered_df.median(),\n",
    "        \"q3\": filtered_df.quantile(0.75),\n",
    "        \"max\": filtered_df.max(),\n",
    "        \"skew\": filtered_df.skew(),\n",
    "        \"iqr\": filtered_df.quantile(0.75) - filtered_df.quantile(0.25), \n",
    "        \"range\": filtered_df.max() - filtered_df.min()\n",
    "    }\n",
    "    \n",
    "    # Filter to requested metrics (always including count)\n",
    "    if metrics:\n",
    "        metrics = {m.lower() for m in metrics}\n",
    "        output_cols = {\"count\": default_metrics[\"count\"]}\n",
    "        for d in default_metrics:\n",
    "            if d != \"count\" and d in metrics:\n",
    "                output_cols[d] = default_metrics[d]\n",
    "    else:\n",
    "        output_cols = default_metrics\n",
    "    \n",
    "    output_df = pd.DataFrame(output_cols)\n",
    "    print(output_df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35af88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_summary(df, columns=None, metrics=None):\n",
    "    \"\"\"\n",
    "    Returns summary dataframe for given columns of categorical type\n",
    "\n",
    "    - params:\n",
    "        - columns: list[str] or None (defaults to non-numeric columns)\n",
    "        - metrics: list[str] subset of ['count', 'missing', 'nunique', 'mode', 'top_freq']\n",
    "    - returns: pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Default to non-numeric columns if no specific columns given\n",
    "    if columns:\n",
    "        columns = [col for col in columns if col in df.columns]\n",
    "    else:\n",
    "        columns = [col for col in df.select_dtypes(include='object')]\n",
    "\n",
    "    if not columns:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    filtered_df = df[columns]\n",
    "\n",
    "    default_metrics = {\n",
    "        \"count\": filtered_df.count(),\n",
    "        \"missing\": filtered_df.isna().sum(),\n",
    "        \"nunique\": filtered_df.nunique(dropna=True),\n",
    "        \"mode\": filtered_df.apply(lambda col: col.mode(dropna=True).iloc[0] if not col.mode(dropna=True).empty else np.nan),\n",
    "        \"top_freq\": filtered_df.apply(lambda col: col.value_counts(dropna=True).iloc[0] if not col.value_counts(dropna=True).empty else 0)\n",
    "    }\n",
    "    if metrics:\n",
    "        metrics = {m.lower() for m in metrics}\n",
    "        output_cols = {\"count\": default_metrics[\"count\"]}\n",
    "        for d in default_metrics:\n",
    "            if d != \"count\" and d in metrics:\n",
    "                output_cols[d] = default_metrics[d]\n",
    "    else:\n",
    "        output_cols = default_metrics\n",
    "\n",
    "    output_df = pd.DataFrame(output_cols)\n",
    "    print(output_df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffed275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mode_stats(df, columns=None, metrics=None):\n",
    "    \"\"\"\n",
    "    Returns summary dataframe for given columns of categorical type\n",
    "\n",
    "    - params:\n",
    "        - columns: list[str] or None\n",
    "        - metrics: list[str] subset of ['mode', 'mode_frequency', 'unique_values', 'most_frequent_values']\n",
    "    - returns: pd.DataFrame\n",
    "    \"\"\"\n",
    "    if columns is None:\n",
    "        columns = df.columns\n",
    "\n",
    "    # Default metrics\n",
    "    all_metrics = ['mode', 'mode_frequency', 'unique_values', 'most_frequent_values']\n",
    "    if metrics is not None:\n",
    "        metrics = [m for m in metrics if m in all_metrics]\n",
    "    else:\n",
    "        metrics = all_metrics\n",
    "\n",
    "    mode_stats = {}\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            stats = {\n",
    "                'mode': df[col].mode().iloc[0] if not df[col].mode().empty else None,\n",
    "                'mode_frequency': df[col].value_counts().iloc[0] if not df[col].value_counts().empty else 0,\n",
    "                'unique_values': df[col].nunique(),\n",
    "                'most_frequent_values': df[col].value_counts().head(3).to_dict()\n",
    "            }\n",
    "            # Only keep requested metrics\n",
    "            mode_stats[col] = {k: stats[k] for k in metrics}\n",
    "    print(mode_stats)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9db6988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_correlation_matrix(df, method='pearson'):\n",
    "    \"\"\"Generate correlation matrix and heatmap for numeric columns\"\"\"\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    if numeric_df.empty:\n",
    "        print(\"No numeric columns found for correlation analysis\")\n",
    "        return None\n",
    "    \n",
    "    correlation_matrix = numeric_df.corr(method=method)\n",
    "    \n",
    "    # Create correlation heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "                square=True, linewidths=0.5)\n",
    "    plt.title(f'Correlation Matrix ({method.title()})')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(correlation_matrix)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e57ec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_distribution_plots(df, columns=None, max_plots=6):\n",
    "    \"\"\"Create distribution plots and histograms for numeric columns\"\"\"\n",
    "    if columns is None:\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    else:\n",
    "        numeric_cols = [col for col in columns if col in df.columns and df[col].dtype in ['int64', 'float64']]\n",
    "    \n",
    "    numeric_cols = numeric_cols[:max_plots]  # Limit number of plots\n",
    "    \n",
    "    if len(numeric_cols) == 0:\n",
    "        print(\"No numeric columns found for distribution plots\")\n",
    "        return\n",
    "    \n",
    "    n_cols = min(3, len(numeric_cols))\n",
    "    n_rows = math.ceil(len(numeric_cols) / n_cols)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "    if n_rows == 1 and n_cols == 1:\n",
    "        axes = [axes]\n",
    "    elif n_rows == 1:\n",
    "        axes = axes\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    for i, col in enumerate(numeric_cols):\n",
    "        if i < len(axes):\n",
    "            axes[i].hist(df[col].dropna(), bins=30, alpha=0.7, edgecolor='black')\n",
    "            axes[i].set_title(f'Distribution of {col}')\n",
    "            axes[i].set_xlabel(col)\n",
    "            axes[i].set_ylabel('Frequency')\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for i in range(len(numeric_cols), len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881f15c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summaries(df, user_query):\n",
    "    \"\"\"\n",
    "    Main function that gets called by the main router.\n",
    "    MUST take (user_query, df) and return df\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Create helper docs (Reimplement with functions)\n",
    "    helper_docs = \"\"\"\n",
    "    - numerical_summary(df, columns=None, metrics=None): Returns a numeric summary DataFrame for given columns. \n",
    "    prints summary of given metrics for given columns in dataframe of numeric type only\n",
    "        - params:\n",
    "            - columns: list[str] or None (defaults to numeric columns)\n",
    "            - metrics: list[str] subset of [\"count\",\"missing\",\"mean\",\"std\",\"min\",\"median\",\"q1\",\"q3\",\"max\",\"skew\",\"range\", \"iqr\"]\n",
    "    - def categorical_summary(df, columns=None, metrics=None)\n",
    "    prints summary of given metrics for given columns in dataframe\n",
    "        - params:\n",
    "            - columns: list[str] or None (defaults to non-numeric columns)\n",
    "            - metrics: list[str] subset of ['count', 'missing', 'nunique', 'mode', 'top_freq']\n",
    "    - def calculate_mode_stats(df, columns=None, metrics=None): \n",
    "    prints summary of given metrics for given columns in dataframe\n",
    "        - params:\n",
    "            - columns: list[str] or None (defaults to non-numeric columns)\n",
    "            - metrics: list[str] subset of ['mode', 'mode_frequency', 'unique_values', 'most_frequent_values']\n",
    "\n",
    "    - generate_correlation_matrix(df, method='pearson'): Create correlation matrix and heatmap for numeric columns\n",
    "    - create_distribution_plots(df, columns=None, max_plots=6): Create histograms for numeric columns\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create message chain\n",
    "    messages = []\n",
    "    messages.append(SystemMessage(content=f\"\"\"\n",
    "    You are a data cleaning agent trying to generate dataset summaries.\n",
    "    \n",
    "    Dataset info: Shape: {df.shape}, Sample: {df.head(3).to_string()}\n",
    "    \n",
    "    Helper functions available (USE PANDAS WHERE POSSIBLE): \n",
    "    {helper_docs}\n",
    "\n",
    "    Libraries available:\n",
    "    - pd (pandas), np (numpy)\n",
    "    - math, re, datetime\n",
    "    - preprocessing, impute (from sklearn)\n",
    "    - plt (matplotlib.pyplot), sns (seaborn)\n",
    "    - stats (from scipy)\n",
    "    \n",
    "    BASIC SUMMARIES\n",
    "    - df.shape(): rows and columns\n",
    "    - 5 number summary (numerical): 'IQR', 'Q3', 'Q1', 'Median', 'Mean' \n",
    "    - (categorical): mode, nunique, top_freq\n",
    "\n",
    "    Rules:\n",
    "    - Return only executable Python code, no explanations, no markdown blocks\n",
    "    - Use helper functions if needed\n",
    "    - For specific columns mentioned in query, pass them as lists to helper functions\n",
    "    - ASSUME DF IS ALREADY DEFINED\n",
    "    - In order to generate a response/message to the user use print statements\n",
    "    print(\"message\")\n",
    "    - Write a detailed print message to summarise actions taken and reasons\n",
    "\n",
    "    Examples:\n",
    "    - \"correlation matrix\" -> generate_correlation_matrix(df)\n",
    "    - \"summary of all data\" -> use multiple helper functions\n",
    "    - \"distribution plots\" -> create_distribution_plots(df)\n",
    "    \"\"\"))\n",
    "    messages.append(HumanMessage(content=f\"User request: {user_query}\"))\n",
    "    \n",
    "    # Call LLM with message chain\n",
    "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\")\n",
    "    response = llm.invoke(messages)\n",
    "    generated_code = response.content.strip()\n",
    "    \n",
    "    # Execute code\n",
    "    try:\n",
    "        original_df = df.copy()\n",
    "        exec(generated_code)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(f\"Generated Code:{generated_code}\")\n",
    "        return original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b618978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST OUT YOUR FEATURE\n",
    "# df = pd.read_csv(\"../sample_data/household_vista_2023_2024.csv\")[0:5000]\n",
    "## Import Data\n",
    "\n",
    "## Run code\n",
    "# get_summaries(df, \"help me visualise distributions for the weight columns\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-cleaning-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
