{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e78be46a",
   "metadata": {},
   "source": [
    "## **Feature:** Pattern Matching\n",
    "\n",
    "**Names:** Tanat\n",
    "\n",
    "### **What it does**\n",
    "[Brief description]\n",
    "\n",
    "### **Helper Functions**\n",
    "[List Helper Functions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2cf187d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get API Key\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"OpenAI API Key not found\")\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "pd.set_option('future.no_silent_downcasting', False)\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import datetime\n",
    "from pint import UnitRegistry\n",
    "from pint.errors import UndefinedUnitError\n",
    "ureg = UnitRegistry()\n",
    "\n",
    "# Langchain imports\n",
    "from langchain.chat_models import ChatOpenAI  \n",
    "from langchain.schema import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dde2f2",
   "metadata": {},
   "source": [
    "**CLASSIFYING PATTERNS**\n",
    "-\n",
    "<hr>\n",
    "\n",
    "**FUNCTIONS**\n",
    "- classify_object_columns(df, patterns)\n",
    "- classify_column(series,patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "43cf0176",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = {\n",
    "    # Multiselect patterns - \"A; B\", \"A/B\", {'X', 'Y', 'Z'}, [1, 2, 3],\n",
    "    \"multiselect\": r\"^\\s*[^,;/|&]+(?:\\s*[,;/|&]\\s*[^,;/|&]+|\\s+(?:and|AND)\\s+[^,;/|&]+)+\\s*$\",\n",
    "    \"multiselect_structured\": r\"^\\s*[\\[\\{]\\s*[^,\\]\\}]+(?:\\s*,\\s*[^,\\]\\}]+)+\\s*[\\]\\}]\\s*$\",\n",
    "\n",
    "    # Numerical values\n",
    "    \"numeric_plain\": r\"^\\s*[-+]?(?:\\d{1,3}(?:[,.\\s]\\d{3})*(?:[,.]\\d+)?|\\d+(?:[,.]\\d+)?)\\s*$\",\n",
    "    \"percentage\": r\"^\\s*[-+]?\\d+(?:[,.]\\d+)?\\s*%\\s*$\",\n",
    "    \"currency\": r\"^\\s*[$€£¥₹¢₽₦₴₪₩]?\\s*[-+]?(?:\\d{1,3}(?:[,.\\s]\\d{3})*(?:[,.]\\d+)?|\\d+(?:[,.]\\d+)?)\\s*(?:USD|EUR|AUD|GBP|INR|JPY|CAD|CHF|SEK|NOK|DKK|CNY|KRW|RUB|BRL|MXN)?\\s*$\",\n",
    "    \"range\": r\"^(?:[^\\d]+)?([-+]?\\d+(?:[.,:]?\\d+)?)\\s*(?:[-–—]\\s*|\\s+(?:to|TO|bis|à|and|AND)\\s+)\\s*([-+]?\\d+(?:[.,:]?\\d+)?)(?:\\s+([a-zA-Z ]+))?\\s*$\",\n",
    "    \"numeric_with_units\": r\"^\\s*(?:\\w+(?:\\s+\\w+)*)?\\s*[-+]?\\d+(?:[,.]\\d+)?\\s*(?:[-–—]\\s*|\\s+(?:to|TO)\\s+)\\s*[-+]?\\d+(?:[,.]\\d+)?\\s*(?:\\w+(?:\\s+\\w+)*)?\\s*$\",\n",
    "    \"scientific\": r\"^\\s*[-+]?\\d+(?:[,.]\\d+)?[eE][-+]?\\d+\\s*$\",   \n",
    "    \n",
    "    # Date-time patterns (not  tested)\n",
    "    \"date_like\": r\"^\\s*(?:\\d{1,2}[/.-]\\d{1,2}[/.-]\\d{2,4}|\\d{4}[/.-]\\d{1,2}[/.-]\\d{1,2})\\s*$\",\n",
    "    \"time_like\": r\"^\\s*(?:\\d{1,2}:\\d{2}(?::\\d{2})?(?:\\s*[APap][Mm])?)\\s*$\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fc25f14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_object_columns(df, patterns):\n",
    "    col_types = {}\n",
    "    object_df = df.select_dtypes(include=['object'])\n",
    "    for col in object_df:\n",
    "        col_type = classify_column(df[col], patterns)\n",
    "        if col_type:\n",
    "            col_types[col] = col_type\n",
    "    return col_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "81ab6798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_column(series, patterns=patterns):\n",
    "    \"\"\"\n",
    "    Classify an object column into a numeric-like pattern if most values match.\n",
    "    \"\"\"\n",
    "    # Remove null values and convert to string\n",
    "    vals = series.dropna().astype(str)\n",
    "    if vals.empty:\n",
    "        return None\n",
    "    \n",
    "    # Get unique values - much more efficient than sampling\n",
    "    unique_vals = vals.unique()[0:30]\n",
    "    total_unique = len(unique_vals)\n",
    "\n",
    "    if total_unique < 10:\n",
    "        min_support = 0.5\n",
    "    elif total_unique < 30:\n",
    "        min_support = 0.6\n",
    "    else:\n",
    "        min_support = 0.7\n",
    "\n",
    "    # Check each pattern\n",
    "    for pattern_name, pattern_regex in patterns.items():\n",
    "        matches = 0\n",
    "        for val in unique_vals:\n",
    "            if re.match(pattern_regex, val.strip()):\n",
    "                matches += 1\n",
    "\n",
    "        # If this pattern matches enough values, return it\n",
    "        if matches / total_unique >= min_support:\n",
    "            return pattern_name\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e678e101",
   "metadata": {},
   "source": [
    "**HANDLING NUMERIC COLUMNS**\n",
    "-\n",
    "<hr>\n",
    "\n",
    "**FUNCTIONS**\n",
    "- clean_numeric_plain(val)\n",
    "- handle_numeric(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7650271c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_numeric_plain(val):\n",
    "    s = str(val).strip()\n",
    "\n",
    "    # Remove spaces, symbols, currency codes, %\n",
    "    s = re.sub(r'\\s+', '', s)\n",
    "    s = re.sub(r'[$€£¥₹¢₽₦₴₪₩]', '', s)\n",
    "    s = re.sub(r'(USD|EUR|AUD|GBP|INR|JPY|CAD|CHF|SEK|NOK|DKK|CNY|KRW|RUB|BRL|MXN)', '', s, flags=re.IGNORECASE)\n",
    "    is_percent = False\n",
    "    if '%' in s:\n",
    "        s = s.replace('%', '')\n",
    "        is_percent = True\n",
    "\n",
    "    # Handle different number formats: 1.234,56 or 1,234.56\n",
    "    if re.match(r'^\\d{1,3}(\\.\\d{3})+,\\d+$', s):\n",
    "        s = s.replace('.', '').replace(',', '.')\n",
    "    elif re.match(r'^\\d{1,3}(,\\d{3})+(\\.\\d+)?$', s):\n",
    "        s = s.replace(',', '')\n",
    "\n",
    "    # Handle any decimal commas and stray commas\n",
    "    elif re.match(r'^\\d+,\\d+$', s):\n",
    "        s = s.replace(',', '.')\n",
    "    s = s.replace(',', '')\n",
    "\n",
    "    # Convert to float\n",
    "    try:\n",
    "        num = float(s)\n",
    "        if is_percent:\n",
    "            num = num / 100\n",
    "        return num\n",
    "    except:\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cab7cd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_numeric(series):\n",
    "    errors = {}\n",
    "    cleaned = [clean_numeric_plain(val) for val in series]\n",
    "    converted = pd.to_numeric(cleaned, errors='coerce')\n",
    "    converted = pd.Series(converted, index=series.index, name=series.name)\n",
    "    for idx, (orig, conv) in enumerate(zip(series, converted)):\n",
    "        if pd.isna(conv) and pd.notna(orig):\n",
    "            if orig not in errors:\n",
    "                errors[orig] = 0\n",
    "            errors[orig] += 1\n",
    "            converted.iloc[idx] = orig\n",
    "    return converted, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae21900",
   "metadata": {},
   "source": [
    "**HANDLING UNIT COLUMNS**\n",
    "-\n",
    "<hr>\n",
    "\n",
    "ureg: pint's unit registry\n",
    "\n",
    "**FUNCTIONS**\n",
    "- unit_exists(unit, ureg)\n",
    "- handle_unit(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4558ec7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to check if pint unit exists\n",
    "def unit_exists(unit, ureg):\n",
    "    try:\n",
    "        ureg.Unit(unit)\n",
    "        return True\n",
    "    except UndefinedUnitError:\n",
    "        return False\n",
    "\n",
    "def handle_units(series):\n",
    "    \"\"\"\n",
    "    Normalize all units to the first unit found in the series and return numeric values.\n",
    "    \"\"\"\n",
    "    errors = {}\n",
    "    ureg = UnitRegistry()    \n",
    "    # Find the first unit in the series\n",
    "    target_unit = None\n",
    "    for text in series.dropna():\n",
    "        match = re.search(r'(\\d+\\.?\\d*)\\s*([a-zA-Z]+)', str(text))\n",
    "        if match and unit_exists(match.group(2), ureg):\n",
    "            target_unit = match.group(2)\n",
    "            break\n",
    "        else:\n",
    "            if str(text) not in errors:\n",
    "                errors[str(text)] = 0\n",
    "            errors[str(text)] += 1\n",
    "    \n",
    "    if not target_unit:\n",
    "        return series, errors\n",
    "\n",
    "    # Helper function within to turn unit strings into numbers\n",
    "    def convert_units(text):\n",
    "        # Handle no match or null\n",
    "        if pd.isna(text):\n",
    "            return None\n",
    "        match = re.search(r'(\\d+\\.?\\d*)\\s*([a-zA-Z]+)', str(text))\n",
    "        if not match:\n",
    "            if str(text) not in errors:\n",
    "                errors[str(text)] = 0\n",
    "            errors[str(text)] += 1\n",
    "            return text\n",
    "\n",
    "        value, unit = match.groups()\n",
    "        try:\n",
    "            quantity = ureg.Quantity(float(value), unit)\n",
    "            converted = quantity.to(target_unit)\n",
    "            return converted.magnitude\n",
    "        except Exception as e:\n",
    "            if str(text) not in errors:\n",
    "                errors[str(text)] = 0\n",
    "            errors[str(text)] += 1\n",
    "            return text\n",
    "            \n",
    "    # Apply convert_unit function\n",
    "    numeric_series = series.apply(convert_units) \n",
    "    numeric_series.name = f\"{series.name or 'values'}_{target_unit}\"\n",
    "    return numeric_series, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f333f3f1",
   "metadata": {},
   "source": [
    "**HANDLING RANGE COLUMNS**\n",
    "-\n",
    "<hr>\n",
    "\n",
    "**FUNCTIONS**\n",
    "- convert_range(val)\n",
    "- handle_range(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8b2fe87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_range(val):\n",
    "    \"\"\"\n",
    "    Extracts numeric ranges and units from strings, computes the midpoint.\n",
    "    Returns a string \"{midpoint} {unit}\"\n",
    "    \"\"\"\n",
    "    s = str(val).strip()\n",
    "    # Match the range pattern\n",
    "    range_regex = r\"^(?:[^\\d]+)?([-+]?\\d+(?:[.,:]?\\d+)?)\\s*(?:[-–—]\\s*|\\s+(?:to|TO|bis|à|and|AND)\\s+)\\s*([-+]?\\d+(?:[.,:]?\\d+)?)(?:\\s+([a-zA-Z ]+))?\\s*$\"\n",
    "    match = re.match(range_regex, s)\n",
    "    if not match:\n",
    "        return s\n",
    "    num1, num2, unit = match.group(1), match.group(2), match.group(3)\n",
    "    # Normalize decimals\n",
    "    num1 = num1.replace(',', '.').replace(':', '.')\n",
    "    num2 = num2.replace(',', '.').replace(':', '.')\n",
    "    try:\n",
    "        n1 = float(num1)\n",
    "        n2 = float(num2)\n",
    "        midpoint = (n1 + n2) / 2\n",
    "    except:\n",
    "        return s\n",
    "    return f\"{midpoint} {unit}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "077ef89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_range(series):\n",
    "    \"\"\"\n",
    "    Applies handle_range to a pandas Series.\n",
    "    Returns a pandas Series with \"{midpoint} {unit}\" or np.nan if parsing fails.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    errors = {}\n",
    "    valid_mask = []\n",
    "    for val in series:\n",
    "        if val is None or (isinstance(val, float)):\n",
    "            result.append(val)\n",
    "            valid_mask.append(False)\n",
    "            continue\n",
    "        cleaned = handle_range(val)\n",
    "        if isinstance(cleaned, str) and cleaned == str(val).strip():\n",
    "            if val not in errors:\n",
    "                errors[val] = 0\n",
    "            errors[val] += 1\n",
    "            result.append(val)\n",
    "            valid_mask.append(False)\n",
    "        else:\n",
    "            result.append(cleaned)\n",
    "            valid_mask.append(True)\n",
    "\n",
    "    result = pd.Series(result)\n",
    "    result.name = series.name\n",
    "\n",
    "    valid_series = result[valid_mask]\n",
    "    converted, unit_errors = handle_units(valid_series)\n",
    "    result.name = converted.name\n",
    "    errors.update(unit_errors)\n",
    "\n",
    "    # Update only valid positions in the result\n",
    "    result.loc[valid_series.index] = converted\n",
    "    return result, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4e7faf",
   "metadata": {},
   "source": [
    "**CONVERTING COLUMNS**\n",
    "-\n",
    "<hr>\n",
    "\n",
    "**FUNCTIONS**\n",
    "- classify_and_convert(df, patterns)\n",
    "- llm_fix_errors(df, all_errors)\n",
    "- object_conversion_with_llm(df, patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a97901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_and_convert(df, patterns):\n",
    "    \"\"\"\n",
    "    Classifies object columns and applies appropriate conversion.\n",
    "    \"\"\"\n",
    "    col_types = classify_object_columns(df,patterns)\n",
    "    if not col_types:\n",
    "        print(\"No patterns detected\")\n",
    "        return df, {}, {}\n",
    "\n",
    "    print(\"Classified columns, Attempting Inital conversion\")\n",
    "    all_errors = {}\n",
    "    for col, col_type in col_types.items():\n",
    "        if col_type in {'multiselect, multiselect_structured'}:\n",
    "            pass \n",
    "        elif col_type == 'range':\n",
    "            converted, errors = handle_range(df[col])\n",
    "        elif col_type in {'percentage', 'numeric_plain', 'currency', 'scientific'}:\n",
    "            converted, errors = handle_numeric(df[col])\n",
    "        elif col_type == 'numeric_with_units':\n",
    "            converted, errors = handle_units(df[col])\n",
    "        else:\n",
    "            continue\n",
    "        # Update df column and rename if name changes\n",
    "        df[col] = converted\n",
    "        if converted.name != col:\n",
    "            df.rename(columns={col: converted.name}, inplace=True)\n",
    "            col_key = converted.name\n",
    "        else:\n",
    "            col_key = col\n",
    "        # Update log with error values\n",
    "        if errors:\n",
    "            all_errors[col_key] = {}\n",
    "            all_errors[col_key]['errors'] = errors\n",
    "            all_errors[col_key]['type'] = col_type\n",
    "    print(\"Initial conversion attempt completed\")\n",
    "    return df, all_errors, col_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "46717c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_fix_errors(df, all_errors):\n",
    "    prompt = \"\"\"\n",
    "    The following columns have already been attempted to convert to numerical columns.\n",
    "    Please suggest Python code to fix these by suggesting appropriate numerical values to replace these error values:\\n\\n\n",
    "    - Assume dataframe already exists stored in variable 'df'\n",
    "    - Import pandas as pd and numpy as np at the start\n",
    "\n",
    "    Rules:\n",
    "    - For open-ended ranges or qualitative values, use reasonable domain assumptions and try to CALCULATE MIDPOINTS\n",
    "    (e.g., max working years is 50, max age is 100, etc.) when calculating midpoints or replacements.\n",
    "    - Print reasonings for your assumptions after any assumptions have been made\n",
    "    (e.g., print('LLM: Assumed 0.25 hours for less than 30 minutes and 5 hours for over 4')\n",
    "    - If no assumptions needed don't assume just replace strings with the appropriate numerical value\n",
    "    - ASSUMING ADDS BIAS TO DATA USE EXACT VALUE WHEN IT MAKES SENSE (NO RANGES)\n",
    "    (e.g., '59.5 employees' -> 59.5, '3.5 times per week' -> 3.5)\n",
    "    - Handle units carefully make sure units allign with other units in the column\n",
    "    - Use this EXACT format to avoid pandas warnings:\n",
    "    df[col] = df[col].replace({'old_value': new_value}).infer_objects(copy=False)\n",
    "    - ONLY convert to np.nan if data doesn't make sense/allign with context and unsure on how to convert\n",
    "    \n",
    "    Example:\n",
    "    df['Age'] = df['Age'].replace({'Under 18': 17, '65+': 70}).infer_objects(copy=False)\n",
    "    print('LLM: Assumed 17 for Under 18 and 70 for 65+ in Age column')\n",
    "\n",
    "    IMPORTANT: Always chain .infer_objects(copy=False) directly after .replace() in the same line\n",
    "    \n",
    "    ONLY GENERATE VALID PYTHON CODE (no markdown blocks, no explanations)\n",
    "    \"\"\"\n",
    "    print(\"Final LLM attempt to fix errors (Might take awhile)\")\n",
    "    errors_context = \"\"\n",
    "    df_context = \"\"\n",
    "    for col, info in all_errors.items():\n",
    "        error_type = info.get('type', 'unknown')\n",
    "        error_values = list(info['errors'].keys())\n",
    "        errors_context += f\"Column: {col}\\nType: {error_type}\\nErrors: {error_values[:10]}\\n\\n\"\n",
    "\n",
    "        df_unique = df[col].dropna().astype(str).unique()\n",
    "        df_unique_len = len(df_unique)\n",
    "        df_unique_vals = \", \".join(df_unique[:20])\n",
    "        df_context += f\"Column:{col}\\nUniques:{df_unique_len}\\nValues:{df_unique_vals}\\n\\n\"\n",
    "\n",
    "    messages = []\n",
    "    messages.append(SystemMessage(prompt))\n",
    "    messages.append(HumanMessage(errors_context))\n",
    "        \n",
    "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\")\n",
    "    response = llm.invoke(messages)\n",
    "    generated_code = response.content.strip()\n",
    "    # print(generated_code)\n",
    "    \n",
    "    try:\n",
    "        original_df = df.copy()\n",
    "        namespace = {\"df\": original_df, \"pd\": pd, \"np\": np}\n",
    "        exec(generated_code, namespace)\n",
    "        df = namespace[\"df\"]\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(f\"Generated Code:{generated_code}\")\n",
    "        return original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a81be89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_conversion_with_llm(df, patterns):\n",
    "    \"\"\"\n",
    "    Runs the full object column conversion pipeline:\n",
    "    1. Classifies and converts object columns.\n",
    "    2. Uses LLM to fix remaining errors.\n",
    "    3. Checks which columns are still object dtype.\n",
    "    Returns: (df, failed_cols, all_errors, col_types)\n",
    "    \"\"\"\n",
    "    # Step 1: Initial classification + conversion \n",
    "    df, all_errors, col_types = classify_and_convert(df, patterns)\n",
    "    # Step 2: LLM fixes any errors\n",
    "    if all_errors:\n",
    "        failed_cols=[]\n",
    "        df = llm_fix_errors(df, all_errors)\n",
    "        # Check for remaining object columns\n",
    "        for col in all_errors.keys():\n",
    "            if col in df.columns and df[col].dtype == 'object':\n",
    "                failed_cols.append(col)\n",
    "        if not failed_cols:\n",
    "            print(\"All error columns have been successfully converted from object dtype.\")\n",
    "        else:\n",
    "            print(f\"The following columns are still object dtype: {failed_cols}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaa64be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pattern_matching(df, user_query):\n",
    "    \"\"\"\n",
    "    Main function that gets called by the main router.\n",
    "    MUST take (user_query, df) and return df\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Create helper docs (Reimplement with functions)\n",
    "    helper_docs = f\"\"\"\n",
    "    VARIABLES AVAILABLE\n",
    "    - patterns: a dict containing regex patterns in order to classify columns\n",
    "    contains patterns for: {\", \".join(patterns.keys())}\n",
    "    sample patterns: {\", \".join(patterns.items()[:5])}\n",
    "\n",
    "    FUNCTIONS AVAILABLE:\n",
    "    - classify_column(series,patterns)\n",
    "    takes a series and classifies them based on dict of regex patterns in patterns\n",
    "    - classify_object_columns(df, patterns)\n",
    "    takes object columns from a df and classfies them with classify_column\n",
    "    - classify_and_convert(df, patterns): \n",
    "    takes df and runs classify_object_columns and attempts to convert them to numerical columns\n",
    "    - object_conversion_with_llm(df, patterns): \n",
    "    \"\"\"\n",
    "    \n",
    "    # Create message chain\n",
    "    messages = []\n",
    "    messages.append(SystemMessage(content=f\"\"\"\n",
    "    You are a data cleaning agent.\n",
    "    \n",
    "    Dataset info: Shape: {df.shape}, Sample: {df.head(3).to_string()}\n",
    "    \n",
    "    Helper functions available:\n",
    "    {helper_docs}\n",
    "\n",
    "    Libraries available:\n",
    "    - pd (pandas), np (numpy)\n",
    "    - math, re, datetime\n",
    "    - preprocessing, impute (from sklearn)\n",
    "    \n",
    "    Rules:\n",
    "    - Return only executable Python code, no explanations, no markdown blocks\n",
    "    - Use helper functions where possible\n",
    "    - Store final result in 'result_df'\n",
    "    - No explanations, just code\n",
    "    \"\"\"))\n",
    "    messages.append(HumanMessage(content=f\"User request: {user_query}\"))\n",
    "    \n",
    "    # Call LLM with message chain\n",
    "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\")\n",
    "    response = llm.invoke(messages)\n",
    "    generated_code = response.content.strip()\n",
    "    \n",
    "    # Execute code\n",
    "    try:\n",
    "        original_df = df.copy()\n",
    "        exec(generated_code)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(f\"Generated Code:{generated_code}\")\n",
    "        return original_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcdc9ce",
   "metadata": {},
   "source": [
    "**TESTING**\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fcac110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"../sample_data/smoke.csv\")[0:5000]\n",
    "df = pd.read_csv(\"../sample_data/Life Expectancy Data.csv\")[0:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ee57e777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No patterns detected\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(          Country  Year      Status  Life expectancy   Adult Mortality  \\\n",
       " 0     Afghanistan  2015  Developing              65.0            263.0   \n",
       " 1     Afghanistan  2014  Developing              59.9            271.0   \n",
       " 2     Afghanistan  2013  Developing              59.9            268.0   \n",
       " 3     Afghanistan  2012  Developing              59.5            272.0   \n",
       " 4     Afghanistan  2011  Developing              59.2            275.0   \n",
       " ...           ...   ...         ...               ...              ...   \n",
       " 2933     Zimbabwe  2004  Developing              44.3            723.0   \n",
       " 2934     Zimbabwe  2003  Developing              44.5            715.0   \n",
       " 2935     Zimbabwe  2002  Developing              44.8             73.0   \n",
       " 2936     Zimbabwe  2001  Developing              45.3            686.0   \n",
       " 2937     Zimbabwe  2000  Developing              46.0            665.0   \n",
       " \n",
       "       infant deaths  Alcohol  percentage expenditure  Hepatitis B  Measles   \\\n",
       " 0                62     0.01               71.279624         65.0      1154   \n",
       " 1                64     0.01               73.523582         62.0       492   \n",
       " 2                66     0.01               73.219243         64.0       430   \n",
       " 3                69     0.01               78.184215         67.0      2787   \n",
       " 4                71     0.01                7.097109         68.0      3013   \n",
       " ...             ...      ...                     ...          ...       ...   \n",
       " 2933             27     4.36                0.000000         68.0        31   \n",
       " 2934             26     4.06                0.000000          7.0       998   \n",
       " 2935             25     4.43                0.000000         73.0       304   \n",
       " 2936             25     1.72                0.000000         76.0       529   \n",
       " 2937             24     1.68                0.000000         79.0      1483   \n",
       " \n",
       "       ...  Polio  Total expenditure  Diphtheria    HIV/AIDS         GDP  \\\n",
       " 0     ...    6.0               8.16         65.0        0.1  584.259210   \n",
       " 1     ...   58.0               8.18         62.0        0.1  612.696514   \n",
       " 2     ...   62.0               8.13         64.0        0.1  631.744976   \n",
       " 3     ...   67.0               8.52         67.0        0.1  669.959000   \n",
       " 4     ...   68.0               7.87         68.0        0.1   63.537231   \n",
       " ...   ...    ...                ...          ...        ...         ...   \n",
       " 2933  ...   67.0               7.13         65.0       33.6  454.366654   \n",
       " 2934  ...    7.0               6.52         68.0       36.7  453.351155   \n",
       " 2935  ...   73.0               6.53         71.0       39.8   57.348340   \n",
       " 2936  ...   76.0               6.16         75.0       42.1  548.587312   \n",
       " 2937  ...   78.0               7.10         78.0       43.5  547.358878   \n",
       " \n",
       "       Population   thinness  1-19 years   thinness 5-9 years  \\\n",
       " 0     33736494.0                   17.2                 17.3   \n",
       " 1       327582.0                   17.5                 17.5   \n",
       " 2     31731688.0                   17.7                 17.7   \n",
       " 3      3696958.0                   17.9                 18.0   \n",
       " 4      2978599.0                   18.2                 18.2   \n",
       " ...          ...                    ...                  ...   \n",
       " 2933  12777511.0                    9.4                  9.4   \n",
       " 2934  12633897.0                    9.8                  9.9   \n",
       " 2935    125525.0                    1.2                  1.3   \n",
       " 2936  12366165.0                    1.6                  1.7   \n",
       " 2937  12222251.0                   11.0                 11.2   \n",
       " \n",
       "       Income composition of resources  Schooling  \n",
       " 0                               0.479       10.1  \n",
       " 1                               0.476       10.0  \n",
       " 2                               0.470        9.9  \n",
       " 3                               0.463        9.8  \n",
       " 4                               0.454        9.5  \n",
       " ...                               ...        ...  \n",
       " 2933                            0.407        9.2  \n",
       " 2934                            0.418        9.5  \n",
       " 2935                            0.427       10.0  \n",
       " 2936                            0.427        9.8  \n",
       " 2937                            0.434        9.8  \n",
       " \n",
       " [2938 rows x 22 columns],\n",
       " [])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_conversion_with_llm(df, patterns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-cleaning-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
