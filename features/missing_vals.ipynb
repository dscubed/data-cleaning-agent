{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "691226d2",
   "metadata": {},
   "source": [
    "## **Feature:** Missing Vals\n",
    "\n",
    "**Names:** Tanat\n",
    "\n",
    "### **What it does**\n",
    "[Brief description]\n",
    "\n",
    "### **Helper Functions**\n",
    "[List Helper Functions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff1f7555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get API Key\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"OpenAI API Key not found\")\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "# Langchain imports\n",
    "from langchain.chat_models import ChatOpenAI  \n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "# from langchain.tools import tool\n",
    "# from langchain.agents import initialize_agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60424d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def analyze_missing_values(df, drop_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Suggest missing value imputation strategies based on heuristics.\n",
    "    \"\"\"\n",
    "    suggestions = {}\n",
    "    for col in df.columns:\n",
    "        missing_pct = df[col].isna().mean()\n",
    "        dtype = df[col].dtype\n",
    "        suggestion = None\n",
    "\n",
    "        if missing_pct == 0:\n",
    "            continue\n",
    "        if missing_pct > drop_threshold:\n",
    "            suggestion = \"Drop column (too many missing values)\"\n",
    "        else:\n",
    "            # Numerical features\n",
    "            if pd.api.types.is_numeric_dtype(dtype):\n",
    "                n_unique = df[col].nunique(dropna=True)\n",
    "                if n_unique < 15:  # numeric but categorical (like codes)\n",
    "                    suggestion = \"Mode imputation (numeric categorical)\"\n",
    "                else:\n",
    "                    non_null = df[col].dropna()\n",
    "                    if len(non_null) < 10:\n",
    "                        suggestion = \"Median imputation (small sample)\"\n",
    "                    else:\n",
    "                        skewness = non_null.skew()\n",
    "                        suggestion = \"Mean imputation\" if abs(skewness) < 1 else \"Median imputation (skewed)\"\n",
    "            \n",
    "            # Categorical features\n",
    "            elif pd.api.types.is_categorical_dtype(dtype) or pd.api.types.is_object_dtype(dtype):\n",
    "                n_unique = df[col].nunique(dropna=True)\n",
    "                if n_unique <= 10:\n",
    "                    suggestion = \"Mode imputation (most frequent)\"\n",
    "                else:\n",
    "                    suggestion = \"Impute with 'Unknown' or predictive model\"\n",
    "\n",
    "            # Boolean features\n",
    "            elif pd.api.types.is_bool_dtype(dtype):\n",
    "                suggestion = \"Mode imputation (True/False)\"\n",
    "\n",
    "            # Datetime features\n",
    "            elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
    "                suggestion = \"Forward/Backward fill or interpolation (time series)\"\n",
    "            \n",
    "            else:\n",
    "                suggestion = \"Custom handling needed\"\n",
    "\n",
    "        suggestions[col] = {\n",
    "            \"dtype\": str(dtype),\n",
    "            \"missing_pct\": round(missing_pct, 3),\n",
    "            \"suggestion\": suggestion\n",
    "        }\n",
    "\n",
    "    return pd.DataFrame.from_dict(suggestions, orient=\"index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "100e6386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_impute(df, drop_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Automatically imputes missing values in a DataFrame based on simple \n",
    "    best-practice heuristics.\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        missing_pct = df[col].isna().mean()\n",
    "        dtype = df[col].dtype\n",
    "\n",
    "        # Drop if too many missing\n",
    "        if missing_pct > drop_threshold:\n",
    "            df = df.drop(columns=[col])\n",
    "            continue\n",
    "\n",
    "        # Numerical features (mean or median)\n",
    "        if np.issubdtype(dtype, np.number):\n",
    "            skewness = df[col].dropna().skew()\n",
    "            if abs(skewness) < 1:\n",
    "                fill_value = df[col].mean()\n",
    "                print(f\"Imputed '{col}' with mean\")\n",
    "            else:\n",
    "                fill_value = df[col].median()\n",
    "                print(f\"'{col}' is skewed, imputed with median\")\n",
    "            df[col] = df[col].fillna(fill_value)\n",
    "\n",
    "        # Categorical features\n",
    "        elif df[col].dtype == \"object\" or pd.api.types.is_categorical_dtype(df[col]):\n",
    "            n_unique = df[col].nunique(dropna=True)\n",
    "            unique_ratio = n_unique / df.shape[0]\n",
    "            # Low Cardinality Fill with median else impute with unknown \n",
    "            if n_unique <= 20 or unique_ratio < 0.05:\n",
    "                fill_value = df[col].mode(dropna=True)[0] if not df[col].mode(dropna=True).empty else \"Unknown\"\n",
    "                df[col] = df[col].fillna(fill_value)\n",
    "                print(f\"{col} has low Cardinality, imputed with mode\")\n",
    "            else:\n",
    "                df[col] = df[col].fillna(\"Unknown\")\n",
    "\n",
    "        # Datetime features\n",
    "        elif np.issubdtype(dtype, np.datetime64):\n",
    "            df[col] = df[col].fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "\n",
    "        # Fallback\n",
    "        else:\n",
    "            df[col] = df[col].fillna(\"Unknown\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "54132b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_vals(df, user_query):\n",
    "    \"\"\"\n",
    "    Main function that gets called by the main router.\n",
    "    MUST take (user_query, df) and return df\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Create helper docs (Reimplement with functions)\n",
    "    helper_docs = \"\"\"\n",
    "    - auto_impute(df, drop_threshold=0.5): Automatically imputes missing values in a DataFrame based on simple best-practice heuristics.\n",
    "    \"\"\"\n",
    "    \n",
    "    suggestions = analyze_missing_values(df)\n",
    "\n",
    "    # Create message chain\n",
    "    messages = []\n",
    "    messages.append(SystemMessage(content=f\"\"\"\n",
    "    You are a data cleaning agent trying to generate dataset summaries.\n",
    "    \n",
    "    Dataset info: Shape: {df.shape}, Sample: {df.head(3).to_string()}\n",
    "    \n",
    "    imputation suggestions: {suggestions if not suggestions.empty else \"No Missing Values!\"}\n",
    "\n",
    "    Helper functions available:\n",
    "    {helper_docs}\n",
    "\n",
    "    Libraries available:\n",
    "    - pd (pandas), np (numpy)\n",
    "    - math, re, datetime\n",
    "    - preprocessing, impute (from sklearn)\n",
    "    \n",
    "    Rules:\n",
    "    - Return only executable Python code, no explanations, no markdown blocks\n",
    "    - Use helper functions if needed\n",
    "    - ASSUME DF IS ALREADY DEFINED\n",
    "    - In order to generate a response/message to the user use print statements\n",
    "    print(\"message\")\n",
    "    - Write a detailed print message to summarise actions taken and reasons\n",
    "    \"\"\"))\n",
    "    messages.append(HumanMessage(content=f\"User request: {user_query}\"))\n",
    "    \n",
    "    # Call LLM with message chain\n",
    "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\")\n",
    "    response = llm.invoke(messages)\n",
    "    generated_code = response.content.strip()\n",
    "    \n",
    "    # Execute code\n",
    "    try:\n",
    "        original_df = df.copy()\n",
    "        exec(generated_code)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(f\"Generated Code:{generated_code}\")\n",
    "        return original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1082194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"../sample_data/household_vista_2023_2024.csv\")\n",
    "# test_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c684d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has been reviewed and there are no missing values present. Therefore, no imputation is necessary. You can proceed with your analysis or any further processing of the data as needed.\n"
     ]
    }
   ],
   "source": [
    "# test_df = missing_vals(df, \"How should i deal with it\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-cleaning-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
