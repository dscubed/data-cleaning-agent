{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8660f73",
   "metadata": {},
   "source": [
    "## **Feature:** Pattern Matching\n",
    "\n",
    "**Names:** Tanat\n",
    "\n",
    "### **What it does**\n",
    "[Brief description]\n",
    "\n",
    "### **Helper Functions**\n",
    "[List Helper Functions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "01f5f6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get API Key\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"OpenAI API Key not found\")\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "pd.set_option('future.no_silent_downcasting', False)\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import datetime\n",
    "from pint import UnitRegistry\n",
    "from pint.errors import UndefinedUnitError\n",
    "ureg = UnitRegistry()\n",
    "\n",
    "# Langchain imports\n",
    "from langchain.chat_models import ChatOpenAI  \n",
    "from langchain.schema import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5120f663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_non_numeric(series: pd.Series):\n",
    "    return series[~series.apply(lambda x: pd.api.types.is_number(x))].dropna().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e098d2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_classify_patterns(df):\n",
    "    \"\"\"\n",
    "    takes a df and returns a string containings suggestions\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create message chain\n",
    "    messages = []\n",
    "    messages.append(SystemMessage(content=f\"\"\"\n",
    "    You are a data cleaning agent.\n",
    "\n",
    "    In data cleaning Pattern matching allows you to find specific \n",
    "    sequences of characters, which can then be used to standardize formats, \n",
    "    remove punctuation and symbols, correct misspellings, and extract key \n",
    "    information, thereby preparing your data for accurate analysis.\n",
    "\n",
    "    For each column analyse the patterns in the column and classify it ACCORDING\n",
    "    TO THESE PRIORITIES, you may classify multiple patterns per column.\n",
    "    - columns to drop: \n",
    "        ids (can't analyse), \n",
    "        constant columns (nuniques=1), \n",
    "        plain texts (long texts: comments, descriptions etc. hard to analyse)\n",
    "    Numeric Columns:\n",
    "        - NUMERIC WITH MISSING VALUES (e.g. \"missing\", \"unknown\", \"not sure\")\n",
    "        - RANGES (columns with 2 numbers and some separator)\n",
    "        small ranges (handle with midpoints), big ranges (one hot encoding))\n",
    "        (17-20, 18->20 years, between 7 - 10 days)\n",
    "        - Units\n",
    "        (10kgs, 30 hours)\n",
    "        - Numeric (currency, percentage, numeric stored as string)\n",
    "        Currencies: 3.213,00 USD -> 3213.00\n",
    "        Percentage: 10.3% -> 0.103\n",
    "        Strings: twenty-two\n",
    "    - Datetime (timestamp, date, time)\n",
    "    - Multiselect (consider one hot encoding)\n",
    "    - Categories \n",
    "        Low Cardinality: <10 unique values - one hot encoding\n",
    "        Moderate Cardinality: 10-30 unique values - feature engineering/drop\n",
    "        High Cardinality: 30+ unique values - feature engineering/drop\n",
    "        - ordinal (label) encoding: natural ranking exists\n",
    "    Also suggest treatment options to handle these patterns\n",
    "    FLAG ANY Inconsistent formatting in same columns\n",
    "    \"\"\"))\n",
    "\n",
    "    col_info = [{\n",
    "        'col_name': col,\n",
    "        'uniques': df[col].unique()[:5],\n",
    "        'nuniques': df[col].nunique(),\n",
    "        'type': df[col].dtype,\n",
    "        'non-numerics': unique_non_numeric(df[col])\n",
    "    } for col in df.select_dtypes(include='object')]\n",
    "    dataset = f\"\"\"\n",
    "    Dataset info: Shape: {df.shape}, \n",
    "    Object columns: {col_info}\n",
    "    \"\"\"\n",
    "\n",
    "    messages.append(HumanMessage(content=dataset))\n",
    "    \n",
    "    # Call LLM with message chain\n",
    "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\")\n",
    "    response = llm.invoke(messages)\n",
    "    return response.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2736226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_numeric_plain(val):\n",
    "    \"\"\"\n",
    "    Handles any spaces, symbols, currency codes, percentages, EU and US decimal\n",
    "    formats etc.\n",
    "    \"\"\"\n",
    "    s = str(val).strip()\n",
    "    # Remove spaces, symbols, currency codes, %\n",
    "    s = re.sub(r'\\s+', '', s)\n",
    "    s = re.sub(r'[$€£¥₹¢₽₦₴₪₩]', '', s)\n",
    "    s = re.sub(r'(USD|EUR|AUD|GBP|INR|JPY|CAD|CHF|SEK|NOK|DKK|CNY|KRW|RUB|BRL|MXN)', '', s, flags=re.IGNORECASE)\n",
    "    is_percent = False\n",
    "    if '%' in s:\n",
    "        s = s.replace('%', '')\n",
    "        is_percent = True\n",
    "    # Handle different number formats: 1.234,56 or 1,234.56\n",
    "    if re.match(r'^\\d{1,3}(\\.\\d{3})+,\\d+$', s):\n",
    "        s = s.replace('.', '').replace(',', '.')\n",
    "    elif re.match(r'^\\d{1,3}(,\\d{3})+(\\.\\d+)?$', s):\n",
    "        s = s.replace(',', '')\n",
    "    # Handle any decimal commas and stray commas\n",
    "    elif re.match(r'^\\d+,\\d+$', s):\n",
    "        s = s.replace(',', '.')\n",
    "    s = s.replace(',', '')\n",
    "    # Convert to float\n",
    "    try:\n",
    "        num = float(s)\n",
    "        if is_percent:\n",
    "            num = num / 100\n",
    "        return num\n",
    "    except:\n",
    "        print(f\"numeric vals: Failed to clean '{s}'\")\n",
    "        return s\n",
    "    \n",
    "def handle_numeric(series):\n",
    "    return series.apply(clean_numeric_plain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c97fa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_range(series):\n",
    "    \"\"\"\"\n",
    "    applies convert_range to series\n",
    "    \"\"\"\n",
    "    return series.apply(convert_range)\n",
    "\n",
    "def convert_range(val):\n",
    "    \"\"\"\n",
    "    Takes first first 2 numeric blocks with no more than 4 character separator\n",
    "    in between and returns midpoint\n",
    "    \"\"\"\n",
    "    s = str(val).strip()\n",
    "    # Match the range pattern\n",
    "    range_regex = r'([\\d.,]+)[\\D]{0,4}([\\d.,]+)'\n",
    "    match = re.search(range_regex, s)\n",
    "    if not match:\n",
    "        return s\n",
    "    \n",
    "    num1, num2 = match.group(1), match.group(2)\n",
    "    try:\n",
    "        n1 = clean_numeric_plain(num1)\n",
    "        n2 = clean_numeric_plain(num2)\n",
    "        midpoint = (n1 + n2) / 2\n",
    "        return midpoint\n",
    "    except:\n",
    "        print(f\"range vals: Failed to clean '{s}'\")\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "32d12cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_units(series):\n",
    "    \"\"\"\n",
    "    Normalize all units to the first unit found in the series.\n",
    "    \"\"\"\n",
    "    ureg = UnitRegistry()\n",
    "    \n",
    "    # Find first valid unit\n",
    "    target_unit = None\n",
    "    for text in series.dropna():\n",
    "        match = re.search(r'(\\d+\\.?\\d*)\\s*([a-zA-Z]+)', str(text))\n",
    "        if match:\n",
    "            try:\n",
    "                ureg.Unit(match.group(2))  # Test if unit exists\n",
    "                target_unit = match.group(2)\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    if not target_unit:\n",
    "        print(f\"No convertible unit found in '{series.name}'\")\n",
    "        return series  # No units found, return as-is\n",
    "    \n",
    "    def convert_unit(text):\n",
    "        if pd.isna(text):\n",
    "            return text\n",
    "            \n",
    "        match = re.search(r'(\\d+\\.?\\d*)\\s*([a-zA-Z]+)', str(text))\n",
    "        if not match:\n",
    "            return text\n",
    "            \n",
    "        value, unit = match.groups()\n",
    "        try:\n",
    "            quantity = ureg.Quantity(float(value), unit)\n",
    "            converted = quantity.to(target_unit)\n",
    "            return converted.magnitude\n",
    "        except:\n",
    "            print(f\"unit vals: Failed to clean '{text}'\")\n",
    "            return text\n",
    "    \n",
    "    result = series.apply(convert_unit)\n",
    "    result.name = f\"{series.name}_{target_unit}\" if series.name else f\"values_{target_unit}\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc62ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pattern_matching(df, user_query):\n",
    "    \"\"\"\n",
    "    Main function that gets called by the main router.\n",
    "    MUST take (df, user_query) and return df\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Create helper docs (Reimplement with functions)\n",
    "    helper_docs = \"\"\"\n",
    "    The following functions returns a cleaned series make sure to assign it df[col] = ...\n",
    "    - handle_numeric(series): Handles any spaces, symbols, currency codes, percentages, EU and US decimal formats ONLY\n",
    "    - handle_range(series): Matches first 2 numeric blocks cleans it and returns its midpoint \n",
    "    - handle_units(series): Picks first unit found and converts series to that unit\n",
    "    \"\"\"\n",
    "\n",
    "    # Create message chain\n",
    "    messages = []\n",
    "    messages.append(SystemMessage(content=f\"\"\"{llm_classify_patterns(df)}\"\"\"))\n",
    "    messages.append(SystemMessage(content=f\"\"\"\n",
    "    You are a data cleaning agent trying to clean any patterns.\n",
    "    \n",
    "    Dataset info: Shape: {df.shape}, Sample: {df.head(3).to_string()}\n",
    "    \n",
    "    Helper functions available (USE PANDAS WHERE POSSIBLE):\n",
    "    {helper_docs}\n",
    "\n",
    "    Libraries available:\n",
    "    - pd (pandas), np (numpy)\n",
    "    - math, re, datetime\n",
    "\n",
    "    Rules:\n",
    "    - Return only executable Python code, no explanations, no markdown blocks\n",
    "    - Use helper functions if needed\n",
    "    - ASSUME DF IS ALREADY DEFINED\n",
    "    - In order to generate a response/message to the user use print statements\n",
    "    print(\"message\")\n",
    "    - Write a detailed print message to summarise actions taken and reasons\n",
    "    - USE .REPLACE TO FIX SMALL INCONSISTENT FORMATTINGS\n",
    "    \"\"\"))\n",
    "    messages.append(HumanMessage(content=f\"User request: {user_query}\"))\n",
    "    \n",
    "    # Call LLM with message chain\n",
    "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\")\n",
    "    response = llm.invoke(messages)\n",
    "    generated_code = response.content.strip()\n",
    "    \n",
    "    # Execute code\n",
    "    try:\n",
    "        original_df = df.copy()\n",
    "        print(generated_code)\n",
    "        exec(generated_code)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(f\"Generated Code:{generated_code}\")\n",
    "        return original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "cc960094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"../sample_data/smoke.csv\")[0:5000]\n",
    "df = pd.read_csv(\"../sample_data/smoke.csv\")[0:5000]\n",
    "test_df = df.copy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-cleaning-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
