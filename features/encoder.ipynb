{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "691226d2",
   "metadata": {},
   "source": [
    "## **Feature:** Dataset Summaries\n",
    "\n",
    "**Names:** Ishan\n",
    "\n",
    "### **What it does**\n",
    "Generates statistical summaries including descriptive statistics (mean, median, mode, variance, std, quartiles), distribution analysis, correlation matrices, and basic visualisations for dataset exploration.\n",
    "\n",
    "### **Helper Functions**\n",
    "- calculate_basic_stats(df, columns=None): Calculate mean, median, std, variance, skewness, kurtosis for numeric columns\n",
    "- calculate_five_number_summary(df, columns=None): Calculate min, Q1, median, Q3, max, IQR for numeric columns\n",
    "- calculate_mode_stats(df, columns=None): Calculate mode, frequency, unique values for all columns\n",
    "- generate_correlation_matrix(df, method='pearson'): Create correlation matrix and heatmap for numeric columns\n",
    "- create_distribution_plots(df, columns=None, max_plots=6): Create histograms for numeric columns\n",
    "- analyse_categorical_columns(df, columns=None, top_n=5): Analyse categorical columns with frequency tables\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1f7555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get API Key\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"OpenAI API Key not found\")\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, impute\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Langchain imports\n",
    "from langchain.chat_models import ChatOpenAI  \n",
    "from langchain.schema import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "881f15c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df, user_query):\n",
    "    \"\"\"\n",
    "    Function to one-hot encode categorical columns in a DataFrame.\n",
    "    df: pandas DataFrame\n",
    "    Returns a new DataFrame with categorical columns one-hot encoded.\n",
    "    \"\"\"\n",
    "\n",
    "    # Detect categorical columns automatically\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    if not categorical_cols:\n",
    "        print(\"No categorical columns found to encode.\")\n",
    "        return df.copy()\n",
    "    \n",
    "    print(f\"Encoding columns: {categorical_cols}\")\n",
    "    \n",
    "    # One-hot encode categorical columns\n",
    "    df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=False)\n",
    "    \n",
    "    print(f\"New DataFrame shape after encoding: {df_encoded.shape}\")\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9b4376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encode(df):\n",
    "    \"\"\"\n",
    "    Function to label encode categorical columns in a DataFrame.\n",
    "    df: pandas DataFrame\n",
    "    Returns a new DataFrame with categorical columns label-encoded.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Detect categorical columns automatically\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    if not categorical_cols:\n",
    "        print(\"No categorical columns found to encode.\")\n",
    "        return df.copy()\n",
    "    \n",
    "    print(f\"Label encoding columns: {categorical_cols}\")\n",
    "    \n",
    "    # Create a copy to avoid modifying original\n",
    "    df_encoded = df.copy()\n",
    "    \n",
    "    # Encode each categorical column\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))\n",
    "    \n",
    "    print(f\"New DataFrame shape after label encoding: {df_encoded.shape}\")\n",
    "    return df_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50f9996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical(df, user_query):\n",
    "    \"\"\"\n",
    "    Main function that gets called by the main router.\n",
    "    MUST take (user_query, df) and return df\n",
    "    \"\"\"\n",
    "\n",
    "    helper_docs = \"\"\"\n",
    "    - One-hot encoding: pd.get_dummies(df, columns=[categorical_cols], drop_first=False)\n",
    "    - Label encoding: sklearn.preprocessing.LabelEncoder()\n",
    "    \"\"\"\n",
    "\n",
    "    messages = []\n",
    "    messages.append(SystemMessage(content=f\"\"\"\n",
    "    You are a data cleaning agent trying to encode categorical columns in a dataset.\n",
    "\n",
    "    Dataset info: Shape: {df.shape}, Sample: {df.head(3).to_string()}\n",
    "\n",
    "    Helper functions available:\n",
    "    {helper_docs}\n",
    "\n",
    "    Libraries available:\n",
    "    - pd (pandas), np (numpy)\n",
    "    - preprocessing (from sklearn)\n",
    "    \n",
    "    Rules:\n",
    "    - Return only executable Python code, no explanations, no markdown blocks\n",
    "    - Automatically detect categorical columns\n",
    "    - If query mentions 'one-hot' or 'one hot', perform one-hot encoding\n",
    "    - If query mentions 'label', perform label encoding\n",
    "    - Store final result in 'encoded_df'\n",
    "    - Always print which columns are encoded and new DataFrame shape\n",
    "    - Use df.copy() at the start to avoid modifying original\n",
    "    \"\"\"))\n",
    "    messages.append(HumanMessage(content=f\"User request: {user_query}\"))\n",
    "\n",
    "    # Call LLM with message chain\n",
    "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\")\n",
    "    response = llm.invoke(messages)\n",
    "    generated_code = response.content.strip()\n",
    "\n",
    "    # Execute code\n",
    "    print(f\"Generated code for encoding:\\n{generated_code}\\n\")\n",
    "    try:\n",
    "        original_df = df.copy()\n",
    "        exec_globals = {\n",
    "            'df': df,\n",
    "            'pd': pd,\n",
    "            'np': np,\n",
    "            'preprocessing': preprocessing,\n",
    "            'LabelEncoder': preprocessing.LabelEncoder,\n",
    "            'print': print\n",
    "        }\n",
    "        exec(generated_code, exec_globals)\n",
    "        return exec_globals.get('encoded_df', df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(f\"Generated Code:{generated_code}\")\n",
    "        return original_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8422802b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-cleaning-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
