{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff1ec261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: import-ipynb in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (0.2)\n",
      "Requirement already satisfied: IPython in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from import-ipynb) (9.4.0)\n",
      "Requirement already satisfied: nbformat in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from import-ipynb) (5.10.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from IPython->import-ipynb) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from IPython->import-ipynb) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from IPython->import-ipynb) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from IPython->import-ipynb) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from IPython->import-ipynb) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from IPython->import-ipynb) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from IPython->import-ipynb) (2.19.2)\n",
      "Requirement already satisfied: stack_data in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from IPython->import-ipynb) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from IPython->import-ipynb) (5.14.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from IPython->import-ipynb) (4.14.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->IPython->import-ipynb) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from jedi>=0.16->IPython->import-ipynb) (0.8.4)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from nbformat->import-ipynb) (2.21.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from nbformat->import-ipynb) (4.25.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from nbformat->import-ipynb) (5.8.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.27.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->import-ipynb) (4.3.8)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->import-ipynb) (311)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from stack_data->IPython->import-ipynb) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from stack_data->IPython->import-ipynb) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from stack_data->IPython->import-ipynb) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: pint in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (0.25)\n",
      "Requirement already satisfied: numpy in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (2.3.2)\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py egg_info did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [15 lines of output]\n",
      "      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "      rather than 'sklearn' for pip commands.\n",
      "      \n",
      "      Here is how to fix this error in the main use cases:\n",
      "      - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "      - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "      - if the 'sklearn' package is used by one of your dependencies,\n",
      "        it would be great if you take some time to track which package uses\n",
      "        'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "      - as a last resort, set the environment variable\n",
      "        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "      \n",
      "      More information is available at\n",
      "      https://github.com/scikit-learn/sklearn-pypi-package\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (0.3.32)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from langchain) (0.3.74)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from langchain) (0.3.9)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from langchain) (0.4.14)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from langchain) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from langchain-community) (3.12.15)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from langchain-community) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from langchain-community) (2.3.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.99.9 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from langchain-openai) (1.99.9)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from langchain-openai) (0.11.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai) (0.16.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2025.7.34)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from langsmith>=0.1.17->langchain) (3.11.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.99.9->langchain-openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\tchan\\anaconda3\\envs\\data-cleaning-agent\\lib\\site-packages (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install necesary packages\n",
    "%pip install import-ipynb\n",
    "\n",
    "%pip install pandas pint numpy sklearn seaborn matplotlib\n",
    "%pip install langchain langchain-community langchain-openai\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fd337c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lang chain imports\n",
    "from langchain.chat_models import ChatOpenAI  \n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Get API KEY\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"OpenAI API Key not found\")\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d628dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import features (TODO: Add features as we develop)\n",
    "import import_ipynb\n",
    "from features.summaries import get_summaries\n",
    "from features.pattern_matching import pattern_matching\n",
    "from features.missing_vals import missing_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a8051915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_query(user_query, df):\n",
    "    # List features for agent \n",
    "    features = \"\"\"\n",
    "    Available features:\n",
    "    - pattern_matching(): handle object columns, preprocessing, cleaning, how to clean data?\n",
    "    - get_summaries(): data summaries, visualise data \n",
    "    - missing_vals(): handling missing data, imputation recommendations\n",
    "    \"\"\"\n",
    "    # - handle_missing_vals(): imputation, missing values \n",
    "    # - detect_outliers(): outliers\n",
    "\n",
    "    # Create message chain\n",
    "    messages = []\n",
    "    messages.append(SystemMessage(content=f\"\"\"\n",
    "    You are a data cleaning agent\n",
    "                                  \n",
    "    Dataset info: Shape: {df.shape}, Sample: {df.head(3).to_string()}\n",
    "\n",
    "    {features}\n",
    "\n",
    "    Route:\n",
    "    - Any general queries about cleaning data go to pattern_matching\n",
    "    - Any questions about analysing data go to get_summaries\n",
    "    - Any questions about missing values go to missing_vals\n",
    "\n",
    "    Rules:\n",
    "    - Each function takes (df, user_query) and returns modified df\n",
    "    - Generate Python code that calls the functions with instructions or suggestions\n",
    "    - Each function call should have a targeted query explaining exactly what to do\n",
    "    - Return only executable Python code, no explanations, NO MARKDOWN BLOCKS\n",
    "    - Only if no actions can be taken, print a descriptive message why\n",
    "    - In order to generate a response/message to the user use print statements\n",
    "    print(\"message\")\n",
    "\n",
    "    Examples:\n",
    "    - User: Find outliers for price and stock, Generated: Single: df = detect_outliers(df, \"find outliers in price, stock\")\n",
    "    - User: Impute numeric columns and generate mean and std for age, Generated: df = handle_missing_vals(df, \"impute numeric columns\"); df = get_summary(df, \"calculate mean and std for age\")\n",
    "    \"\"\"))\n",
    "    messages.append(HumanMessage(content=f\"User request: {user_query}\"))\n",
    "\n",
    "    # Call LLM\n",
    "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\")\n",
    "    response = llm.invoke(messages)\n",
    "    generated_code = response.content.strip()\n",
    "    print(generated_code)\n",
    "\n",
    "    # Execute AI generated code\n",
    "    try:\n",
    "        original_df = df.copy()\n",
    "        exec(generated_code)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(f\"Generated Code:{generated_code}\")\n",
    "        return original_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "76c70202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_load_dataset():\n",
    "    print(\"LOAD YOUR DATASET TO GET STARTED!\")\n",
    "    \n",
    "    datasets_path = \"datasets\"\n",
    "    if os.path.exists(datasets_path):\n",
    "        file_paths = [f for f in os.listdir(datasets_path) if f.lower().endswith('.csv')]\n",
    "        if file_paths:\n",
    "            print(f\"CSV files in '{datasets_path}':\")\n",
    "            for i, fname in enumerate(file_paths):\n",
    "                print(f\"{i+1}. {fname}\")\n",
    "        else:\n",
    "            print(\"No CSV files found in 'datasets' folder.\")\n",
    "            return\n",
    "    else:\n",
    "        print(f\"'{datasets_path}' folder not found.\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\nNot seeing your data? Make sure your CSV file is in 'datasets' folder\")\n",
    "    print(\"Type x to exit.\")\n",
    "    user_file = input(\"To load your dataset, input either the number or name of your desired CSV: \")\n",
    "\n",
    "    if user_file.lower() == \"x\":\n",
    "        print(\"Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Try to load by number\n",
    "    try:\n",
    "        idx = int(user_file) - 1\n",
    "        if 0 <= idx < len(file_paths):\n",
    "            selected_file = file_paths[idx]\n",
    "        else:\n",
    "            print(\"Invalid number.\")\n",
    "            return\n",
    "    except ValueError:\n",
    "        # Try to load by name\n",
    "        if user_file in file_paths:\n",
    "            selected_file = user_file\n",
    "        else:\n",
    "            print(\"File not found.\")\n",
    "            return\n",
    "\n",
    "    df = pd.read_csv(os.path.join(datasets_path, selected_file))\n",
    "    print(f\"\\nLoaded '{selected_file}' with shape {df.shape}\")\n",
    "    print(df.head(5))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "266a50ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_actions(df):\n",
    "    out_path = \"datasets_out\"\n",
    "    while True:\n",
    "        print(\"\\nCommands:\")\n",
    "        print(\"1. View dataframe (head)\")\n",
    "        print(\"2. Output dataframe to CSV\")\n",
    "        print(\"x. Exit\")\n",
    "        user_query = input(\"\\nEnter a command number or a data cleaning/query command: \")\n",
    "        if user_query.lower() == \"x\":\n",
    "            print(\"Exiting.\")\n",
    "            return df\n",
    "        elif user_query == \"1\":\n",
    "            print(df.head())\n",
    "            _ = input(\"enter anything to continue\")\n",
    "        elif user_query == \"2\":\n",
    "            if not os.path.exists(out_path):\n",
    "                os.makedirs(out_path)\n",
    "            out_file = os.path.join(out_path, \"output.csv\")\n",
    "            df.to_csv(out_file, index=False)\n",
    "            print(f\"Dataframe saved to {out_file}\")\n",
    "            _ = input(\"enter anything to continue\")\n",
    "        else:\n",
    "            df = route_query(user_query, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1484df2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    df = user_load_dataset()\n",
    "    df = user_actions(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bf9269",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0389ce11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "df = pd.read_csv('datasets/smoke.csv')\n",
    "test_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59ec888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df = pattern_matching(df, \"handle object columns, preprocessing, cleaning\")\n",
      "df['State'] = df['State'].replace({'\\s+': ''}, regex=True)  # Remove any extra spaces\n",
      "df['Smoke everyday'] = handle_numeric(df['Smoke everyday'])\n",
      "df['Smoke some days'] = handle_numeric(df['Smoke some days'])\n",
      "df['Former smoker'] = handle_numeric(df['Former smoker'])\n",
      "df['Never smoked'] = handle_numeric(df['Never smoked'])\n",
      "\n",
      "print(\"Object columns have been preprocessed and cleaned. The 'State' column had extra spaces removed, and all percentage columns have been converted to numeric format for consistency.\")\n",
      "numeric vals: Failed to clean 'twenty-threepoint6percent'\n",
      "Object columns have been preprocessed and cleaned. The 'State' column had extra spaces removed, and all percentage columns have been converted to numeric format for consistency.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "State",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Smoke everyday",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Smoke some days",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Former smoker",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Never smoked",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "78c9f0b5-0f82-487a-917c-545d1953585b",
       "rows": [
        [
         "0",
         "2010",
         "AL",
         "0.156",
         "0.063",
         "0.239",
         "0.542"
        ],
        [
         "1",
         "2010",
         "AK",
         "0.135",
         "0.068",
         "0.261",
         "0.536"
        ],
        [
         "2",
         "2010",
         "AZ",
         "0.107",
         "0.044000000000000004",
         "0.27899999999999997",
         "0.5710000000000001"
        ],
        [
         "3",
         "2100",
         "Arkansas",
         "0.17300000000000001",
         "0.055999999999999994",
         "0.24100000000000002",
         "0.53"
        ],
        [
         "4",
         "2010",
         "California",
         "0.075",
         "0.046",
         "0.231",
         "0.648"
        ],
        [
         "5",
         "2010",
         "Colorado",
         "0.114",
         "0.046",
         "0.247",
         "0.593"
        ],
        [
         "6",
         "2010",
         "Connecticut",
         "0.092",
         "0.04",
         "1.05",
         "0.5760000000000001"
        ],
        [
         "7",
         "2010",
         "Delaware",
         "0.128",
         "0.045",
         "0.268",
         "0.56"
        ],
        [
         "8",
         "2010",
         "DistrictofColumbia",
         "0.1",
         "0.057",
         "0.23399999999999999",
         "0.61"
        ],
        [
         "9",
         "2010",
         "Florida",
         "0.12",
         "0.052000000000000005",
         "0.298",
         "0.53"
        ],
        [
         "10",
         "2001",
         "Georgia",
         "0.128",
         "0.048",
         "0.231",
         "0.593"
        ],
        [
         "11",
         "2010",
         "Guam",
         "0.19699999999999998",
         "0.061",
         "0.166",
         "0.5760000000000001"
        ],
        [
         "12",
         "2010",
         "Hawaii",
         "0.107",
         "0.038",
         "0.253",
         "0.602"
        ],
        [
         "13",
         "2010",
         "Idaho",
         "0.113",
         "0.044000000000000004",
         "0.22899999999999998",
         "0.615"
        ],
        [
         "14",
         "2010",
         "Illinois",
         "0.115",
         "0.054000000000000006",
         "twenty-threepoint6percent",
         "0.595"
        ],
        [
         "15",
         "2010",
         "Indiana",
         "0.163",
         "0.05",
         "0.251",
         "0.537"
        ],
        [
         "16",
         "2010",
         "Iowa",
         "0.121",
         "0.040999999999999995",
         "0.23399999999999999",
         "0.604"
        ],
        [
         "17",
         "2010",
         "Kansas",
         "0.11900000000000001",
         "0.051",
         "0.242",
         "0.588"
        ],
        [
         "18",
         "2010",
         "Kentucky",
         "0.193",
         "0.055",
         "0.26",
         "0.49200000000000005"
        ],
        [
         "19",
         "2010",
         "Louisiana",
         "0.159",
         "0.062",
         "0.22",
         "0.56"
        ],
        [
         "20",
         "2010",
         "Maine",
         "0.139",
         "0.043",
         "0.302",
         "0.516"
        ],
        [
         "21",
         "2010",
         "Maryland",
         "0.105",
         "0.047",
         "0.239",
         "0.609"
        ],
        [
         "22",
         "2010",
         "Massachusetts",
         "0.102",
         "0.039",
         "0.293",
         "0.5660000000000001"
        ],
        [
         "23",
         "2010",
         "Michigan",
         "0.135",
         "0.054000000000000006",
         "0.253",
         "0.557"
        ],
        [
         "24",
         "2010",
         "Minnesota",
         "0.113",
         "0.036000000000000004",
         "0.259",
         "0.5920000000000001"
        ],
        [
         "25",
         "2010",
         "Mississippi",
         "0.171",
         "0.057999999999999996",
         "0.22",
         "0.55"
        ],
        [
         "26",
         "2010",
         "Missouri",
         "0.166",
         "0.044000000000000004",
         "0.261",
         "0.528"
        ],
        [
         "27",
         "2010",
         "Montana",
         "0.135",
         "0.053",
         "0.272",
         "0.54"
        ],
        [
         "28",
         "2010",
         "Nationwide(StatesandDC)",
         "0.124",
         "0.048",
         "0.251",
         "0.5660000000000001"
        ],
        [
         "29",
         "2010",
         "Nationwide(States,DC,andTerritories)",
         "0.12300000000000001",
         "0.048",
         "0.247",
         "0.568"
        ],
        [
         "30",
         "2010",
         "Nebraska",
         "0.125",
         "0.047",
         "0.252",
         "0.5760000000000001"
        ],
        [
         "31",
         "2010",
         "Nevada",
         "0.165",
         "0.049",
         "0.258",
         "0.528"
        ],
        [
         "32",
         "2010",
         "NewHampshire",
         "0.124",
         "0.045",
         "0.307",
         "0.524"
        ],
        [
         "33",
         "2010",
         "NewJersey",
         "0.102",
         "0.042",
         "0.261",
         "0.594"
        ],
        [
         "34",
         "2010",
         "NewMexico",
         "0.114",
         "0.071",
         "0.247",
         "0.569"
        ],
        [
         "35",
         "2010",
         "NewYork",
         "0.105",
         "0.05",
         "0.268",
         "0.578"
        ],
        [
         "36",
         "2010",
         "NorthCarolina",
         "0.14300000000000002",
         "0.054000000000000006",
         "0.245",
         "0.5579999999999999"
        ],
        [
         "37",
         "2010",
         "NorthDakota",
         "0.122",
         "0.051",
         "0.24100000000000002",
         "0.586"
        ],
        [
         "38",
         "2010",
         "Ohio",
         "0.171",
         "0.054000000000000006",
         "0.24600000000000002",
         "0.529"
        ],
        [
         "39",
         "2010",
         "Oklahoma",
         "0.175",
         "0.062",
         "0.243",
         "0.52"
        ],
        [
         "40",
         "2010",
         "Oregon",
         "0.11",
         "0.040999999999999995",
         "0.282",
         "0.5670000000000001"
        ],
        [
         "41",
         "2010",
         "Pennsylvania",
         "0.134",
         "0.05",
         "0.262",
         "0.5539999999999999"
        ],
        [
         "42",
         "2010",
         "PuertoRico",
         "0.075",
         "0.044000000000000004",
         "0.17300000000000001",
         "0.708"
        ],
        [
         "43",
         "2010",
         "RhodeIsland",
         "0.109",
         "0.048",
         "0.284",
         "0.5589999999999999"
        ],
        [
         "44",
         "2010",
         "SouthCarolina",
         "0.14",
         "0.07",
         "0.24100000000000002",
         "0.5489999999999999"
        ],
        [
         "45",
         "2010",
         "SouthDakota",
         "0.113",
         "0.040999999999999995",
         "0.27",
         "0.5760000000000001"
        ],
        [
         "46",
         "2010",
         "Tennessee",
         "0.157",
         "0.044000000000000004",
         "0.22899999999999998",
         "0.57"
        ],
        [
         "47",
         "2010",
         "Texas",
         "0.105",
         "0.053",
         "0.213",
         "0.629"
        ],
        [
         "48",
         "2010",
         "Utah",
         "0.064",
         "0.027000000000000003",
         "0.14300000000000002",
         "0.7659999999999999"
        ],
        [
         "49",
         "2010",
         "Vermont",
         "0.111",
         "0.042",
         "0.307",
         "0.54"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 876
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>State</th>\n",
       "      <th>Smoke everyday</th>\n",
       "      <th>Smoke some days</th>\n",
       "      <th>Former smoker</th>\n",
       "      <th>Never smoked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>AL</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>AK</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>AZ</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2100</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>California</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>1995</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>1995</td>\n",
       "      <td>Washington</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>1995</td>\n",
       "      <td>WestVirginia</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>1995</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>1995</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>876 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year         State  Smoke everyday  Smoke some days Former smoker  \\\n",
       "0    2010            AL           0.156            0.063         0.239   \n",
       "1    2010            AK           0.135            0.068         0.261   \n",
       "2    2010            AZ           0.107            0.044         0.279   \n",
       "3    2100      Arkansas           0.173            0.056         0.241   \n",
       "4    2010    California           0.075            0.046         0.231   \n",
       "..    ...           ...             ...              ...           ...   \n",
       "871  1995      Virginia           0.187            0.027         0.252   \n",
       "872  1995    Washington           0.175            0.024         0.299   \n",
       "873  1995  WestVirginia           0.237            0.019         0.233   \n",
       "874  1995     Wisconsin           0.182            0.035         0.276   \n",
       "875  1995       Wyoming           0.191            0.029         0.268   \n",
       "\n",
       "     Never smoked  \n",
       "0           0.542  \n",
       "1           0.536  \n",
       "2           0.571  \n",
       "3           0.530  \n",
       "4           0.648  \n",
       "..            ...  \n",
       "871         0.535  \n",
       "872         0.502  \n",
       "873         0.511  \n",
       "874         0.507  \n",
       "875         0.512  \n",
       "\n",
       "[876 rows x 6 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_query = \"how to clean data\"\n",
    "route_query(user_query, df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-cleaning-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
